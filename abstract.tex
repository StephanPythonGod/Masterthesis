The resurgence of interest in conversational information seeking, reignited by the boom of systems like ChatGPT and large language models in general, faces challenges such as knowledge extension, hallucination, and AI interpretability. Overcoming these hurdles necessitates the development of retriever-reader systems, yet constructing such systems from scratch for real-world use cases remains underexplored in current research. This thesis proposes a comprehensive framework for retrieval-augmented generation (RAG)-based conversational question-answering, comprising four components: Extractor, Contextual Query Understanding (CQU), Retriever, and Reader. We delineate the problem field, challenges, and solutions for each component, focusing on leveraging existing Retriever or Reader models rather than reinventing them. We address challenges in the Retriever, proposing solutions based on synthetic data for knowledge source challenges and various methods such as Mixture-of-Experts for evidence set challenges. For the Extract component, we propose a pipeline combination of operations. The Reader's task is broken down into multiple micro challenges and proposes solutions for them based on fine-tuning or post-processing of the evidence set. Applying this framework, we develop an exemplary question-answering chatbot for Heidelberg University's examination regulations. Evaluation uncovers bottlenecks in the Retriever and Extractor components, highlights the drawbacks of smaller language models like Llama2-7B-chat compared to larger models like gpt-3.5-turbo, and emphasizes the limitations of synthetic data for automatic evaluation, primarily applicable to factoid questions. 