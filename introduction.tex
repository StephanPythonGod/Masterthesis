First and foremost, thank you for considering this thesis, which is tailored for specialists in the field of computer science and related disciplines who are interested in constructing conversational question-answering systems.

\section{Motivation}

The journey of exploring natural language querying dates back to as early as 1961, with researchers embarking on projects like Baseball \cite{green_baseball_1961}, a program designed to respond to users' natural language queries within the domain of baseball. The advent of conversational assistants such as Alexa, Siri, and Cortana further fueled interest in conversational information seeking. In 2019, the establishment of the TREC \gls{cast} aimed to nurture \gls{cis} as an active research field and provide large-scale reusable test beds. However, the true surge in user engagement came with the release of ChatGPT by OpenAI in November 2022, which garnered an astounding one million users within five days \cite{demandsage2022chatgpt}.

Since the widespread adoption of ChatGPT, interest in conversational information seeking has surged once again. However, using a generative \gls{llm}:

\begin{enumerate}
    \item Parameterized Knowledge: Expansion or updating of knowledge is challenging.
    \item Explainability: Understanding the rationale behind predictions is difficult.
    \item Hallucination: The model may invent seemingly factual information not present in the underlying knowledge source.
\end{enumerate}

These limitations render the sole use of generative models inadequate for practical conversational information seeking use cases. Consequently, researchers have explored various approaches to address these issues and develop conversational information seeking systems that mimic human-like conversations \cite{ferrucci_introduction_2012,guu_realm_2020,lewis_retrieval-augmented_2021,nakano_webgpt_2022}. Among these approaches, \gls{rag} \cite{lewis_retrieval-augmented_2021} has emerged as a leading solution, evident in trending frameworks like Langchain \cite{noauthor_question_nodate} and even ChatGPT itself \cite{noauthor_chatgpt_2023}.

However, despite advancements in research, there is a notable absence of papers detailing the adoption of these techniques in real-world use cases. To our knowledge, only two such papers exist \cite{feng_dialdoc_2021,gholami_zero-shot_2021}, which do not comprehensively address the entire problem domain associated with this task and fail to leverage modern possibilities with \gls{llm}s.

\section{Objectives and Contributions}

This thesis aims to bridge the gap in the development of conversational question answering systems by providing a comprehensive overview of the technical challenges involved and guiding readers in creating their own use-case-specific systems. We delve into the problem domain of a \gls{rag} based conversational question answering system and introduce \gls{conrag}, a framework comprising four key components: Extract, CQU, Retriever, and Reader. We evaluate this framework by implementing a \gls{convqa} system based on the examination regulations of Heidelberg University. Additionally, we discuss various evaluation approaches and considerations specific to such systems. In summary, the core contributions of this thesis are as follows:

\begin{itemize}
    \item Providing a holistic overview of the challenges in conversational question answering system tailored to a specific document collection.
    \item Breaking down the extraction of passages from a document collection into pipelinable operations.
    \item Identifying challenges faced by the Retriever component towards both the knowledge base and the evidence set.
    \item Decomposing the task of the Reader component into micro-challenges and proposing solutions for them.
    \item Offering multiple approaches for evaluating conversational question answering systems.
    \item Highlighting the limitations of synthetic data for system evaluation.
    \item Providing insights into the current bottlenecks of use-case-specific \gls{convqa} systems.
\end{itemize}

We recommend any reader interested in building their own conversational question answering system to start with this thesis as a foundational guide. They can then proceed to build a basic system similar to Section \ref{sec:setup} and evaluate it in an end-to-end manner as described in Section \ref{subsec:rag-eval}. This approach provides the quickest way to understand the specific challenges of their use case and how to further iterate and improve their system.

\section{Thesis Structure}

The construction of a conversational question answering system is approached in two stages within this thesis. Firstly, we focus on question answering based on a single natural language query, followed by the addition of the conversational component. Thus, Chapter \ref{chap:grundlagen} provides a comprehensive overview. Section \ref{sec:qa} presents various approaches and concepts in the field of question answering, while Section \ref{sec:cqa} extends this perspective to include conversational elements. Narrowing down the range of potential solutions, Chapter \ref{chap:main} introduces the \gls{conrag} framework, which lays out the spectrum of challenges, from handling document collections to enabling conversational question answering. It's important to note that we streamline the choice of possible implementations to a system consisting of four distinct components: Extract, CQU, Retriever and Reader. The validation of this newly established system approach is conducted in a proof-of-concept (POC) manner in Chapter \ref{chap:eval}. Here, we implement and evaluate an exemplary system using the collection of examination regulations from Heidelberg University. This chapter also includes insightful reflections on the evaluation of conversational question answering systems. This concludes the content outline of this thesis.
