Das Interesse an der Entwicklung von Systemen für die konversationelle Informations\-suche hat durch den Boom von ChatGPT und Large Language Modellen im generellen stark zugenommen. Jedoch ist eine alleinige Verwendung von ChatGPT aufgrund von Herausforderungen wie der Aktualisierung und Veränderung von Wissen, Halluzinationen oder der Interpretierbarkeit von KI nicht ausreichend. Die Bewältigung dieser Hürden erfordert die Entwicklung von Retriever-Reader-Systemen. Allerdings ist die Konstruktion solcher Systeme für reale Anwendungsfälle in der aktuellen Forschung noch nicht ausreichend abgedeckt. Diese Arbeit schlägt ein umfassendes Rahmenwerk für Retrieval-Augmented Generation (RAG)-basierte konversationelle Frage-Antwort-Systeme vor, das vier Komponenten umfasst: Extractor, Contextual Query Understanding (CQU), Retriever und Reader. Es werden das Problemfeld, die Herausforderungen und Lösungsansätze für jede Komponente beschrieben, wobei der Fokus darauf liegt, bestehende Retriever- oder Reader-Modelle zu nutzen, anstatt neue Architekturen zu entwickeln. Für die Herausforderungen im Bereich des Retrievers werden Lösungen vorgeschlagen, die auf synthetischen Daten für Probleme im Zusammenhang mit dem Datensatz im generellen und verschiedenen Methoden wie Mixture-of-Experts für Probleme im Zusammenhang mit dem Evidence Set basieren. Für die Extract-Komponente wird eine pipelinefähige Kombination von Operationen vorgeschlagen. Die Aufgabe des Readers wird in mehrere kleinere Herausforderungen unterteilt, für die Lösungsansätze basierend auf Fine-Tuning oder Nachbearbeitung des Evidence Sets entwickelt werden. Unter Verwendung dieses Frameworks wird ein beispielhafter Frage-Antwort-Chatbot für die Prüfungsordnung der Universität Heidelberg entwickelt. Die Evaluation dieses Chatbots zeigt Engpässe in den Komponenten Retriever und Extractor auf, hebt die Nachteile kleinerer Sprachmodelle wie Llama2-7B-chat im Vergleich zu größeren Modellen wie gpt-3.5-turbo hervor und unterstreicht die Grenzen synthetischer Daten für die automatische Evaluation, die vor allem nur für faktoide Fragen anwendbar sind.