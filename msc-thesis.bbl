\begin{thebibliography}{10}

\bibitem{farea_evaluation_2022}
Amer Farea, Zhen Yang, Kien Duong, Nadeesha Perera, and Frank Emmert-Streib.
\newblock Evaluation of question answering systems: Complexity of judging a natural language.

\bibitem{zhu_retrieving_2021}
Fengbin Zhu, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, and Tat-Seng Chua.
\newblock Retrieving and reading: A comprehensive survey on open-domain question answering.

\bibitem{green_baseball_1961}
Bert~F. Green, Alice~K. Wolf, Carol Chomsky, and Kenneth Laughery.
\newblock Baseball: an automatic question-answerer.
\newblock In {\em Papers presented at the May 9-11, 1961, western joint {IRE}-{AIEE}-{ACM} computer conference}, {IRE}-{AIEE}-{ACM} '61 (Western), pages 219--224. Association for Computing Machinery.

\bibitem{voorhees_trec-8_1999}
E.~Voorhees.
\newblock The {TREC}-8 question answering track report.

\bibitem{ferrucci_introduction_2012}
D.~A. Ferrucci.
\newblock Introduction to this is watson.
\newblock 56(3):1:1--1:15.
\newblock Conference Name: {IBM} Journal of Research and Development.

\bibitem{jurafsky_speech_2023}
Dan Jurafsky and James~H. Martin.
\newblock {\em Speech and Language Processing}.
\newblock 3 edition.

\bibitem{hao_recent_2022}
Tianyong Hao, Xinxin Li, Yulan He, Fu~Lee Wang, and Yingying Qu.
\newblock Recent progress in leveraging deep learning methods for question answering.
\newblock 34(4):2765--2783.

\bibitem{etezadi_state_2023}
Romina Etezadi and Mehrnoush Shamsfard.
\newblock The state of the art in open domain complex question answering: a survey.
\newblock 53(4):4124--4144.

\bibitem{zhang_survey_2023}
Qin Zhang, Shangsi Chen, Dongkuan Xu, Qingqing Cao, Xiaojun Chen, Trevor Cohn, and Meng Fang.
\newblock A survey for efficient open domain question answering.
\newblock In {\em Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 14447--14465. Association for Computational Linguistics.

\bibitem{mishra_survey_2016}
Amit Mishra and Sanjay~Kumar Jain.
\newblock A survey on question answering systems with classification.
\newblock 28(3):345--361.

\bibitem{mcdonald_detect_2022}
Tavish {McDonald}, Brian Tsan, Amar Saini, Juanita Ordonez, Luis Gutierrez, Phan Nguyen, Blake Mason, and Brenda Ng.
\newblock Detect, retrieve, comprehend: A flexible framework for zero-shot document-level question answering.

\bibitem{dasigi_dataset_2021}
Pradeep Dasigi, Kyle Lo, Iz~Beltagy, Arman Cohan, Noah~A. Smith, and Matt Gardner.
\newblock A dataset of information-seeking questions and answers anchored in research papers.

\bibitem{zamani_conversational_2023}
Hamed Zamani, Johanne~R. Trippas, Jeff Dalton, and Filip Radlinski.
\newblock Conversational information seeking.

\bibitem{rajpurkar_squad_2016}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.
\newblock {SQuAD}: 100,000+ questions for machine comprehension of text.

\bibitem{dimitrakis_survey_2020}
Eleftherios Dimitrakis, Konstantinos Sgontzos, and Yannis Tzitzikas.
\newblock A survey on question answering systems over linked data and documents.
\newblock 55(2):233--259.

\bibitem{roberts_how_2020}
Adam Roberts, Colin Raffel, and Noam Shazeer.
\newblock How much knowledge can you pack into the parameters of a language model?
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ({EMNLP})}, pages 5418--5426. Association for Computational Linguistics.

\bibitem{harabagiu_open_domain_2003}
Sanda~M. Harabagiu, Steven~J. Maiorano, and Marius~A. Pasca.
\newblock Open-domain textual question answering techniques.
\newblock 9(3):231--267.
\newblock Publisher: Cambridge University Press.

\bibitem{nassiri_transformer_2023}
Khalid Nassiri and Moulay Akhloufi.
\newblock Transformer models used for text-based question answering systems.
\newblock 53(9):10602--10635.

\bibitem{lewis_retrieval-augmented_2021}
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.
\newblock Retrieval-augmented generation for knowledge-intensive {NLP} tasks.

\bibitem{guu_realm_2020}
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang.
\newblock {REALM}: Retrieval-augmented language model pre-training.

\bibitem{nishida_retrieve-and-read_2018}
Kyosuke Nishida, Itsumi Saito, Atsushi Otsuka, Hisako Asano, and Junji Tomita.
\newblock Retrieve-and-read: Multi-task learning of information retrieval and reading comprehension.
\newblock In {\em Proceedings of the 27th {ACM} International Conference on Information and Knowledge Management}, pages 647--656.

\bibitem{wang_modern_2022}
Zhen Wang.
\newblock Modern question answering datasets and benchmarks: A survey.
\newblock Publisher: {arXiv} Version Number: 1.

\bibitem{tito_document_2021}
Rubèn Tito, Dimosthenis Karatzas, and Ernest Valveny.
\newblock Document collection visual question answering.
\newblock volume 12822, pages 778--792.

\bibitem{wang_multi-passage_2019}
Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, and Bing Xiang.
\newblock Multi-passage {BERT}: A globally normalized {BERT} model for open-domain question answering.

\bibitem{liu_dense_2021}
Ye~Liu, Kazuma Hashimoto, Yingbo Zhou, Semih Yavuz, Caiming Xiong, and Philip~S. Yu.
\newblock Dense hierarchical retrieval for open-domain question answering.

\bibitem{mathew_document_2021}
Minesh Mathew, Ruben Tito, Dimosthenis Karatzas, R.~Manmatha, and C.~V. Jawahar.
\newblock Document visual question answering challenge 2020.

\bibitem{li_dit_2022}
Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, and Furu Wei.
\newblock {DiT}: Self-supervised pre-training for document image transformer.

\bibitem{meuschke_benchmark_2023}
Norman Meuschke, Apurva Jagdale, Timo Spinde, Jelena Mitrovic, and Bela Gipp.
\newblock A benchmark of {PDF} information extraction tools using a multi-task and multi-domain evaluation framework for academic documents.
\newblock volume 13972, pages 383--405.

\bibitem{noauthor_langchain-ailangchain_nodate}
langchain-ai/langchain: Building applications with {LLMs} through composability.

\bibitem{noauthor_chatgpt_2023}
{ChatGPT} retrieval plugin.
\newblock original-date: 2023-03-23T06:06:22Z.

\bibitem{karpukhin_dense_2020}
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.
\newblock Dense passage retrieval for open-domain question answering.

\end{thebibliography}
