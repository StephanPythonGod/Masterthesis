\begin{thebibliography}{}

\bibitem[noa, 2023a]{noauthor_deepsparse_2023}
 (2023a).
\newblock {DeepSparse}.
\newblock original-date: 2020-12-14T17:40:38Z.

\bibitem[noa, 2023b]{noauthor_quantize_nodate}
 (2023b).
\newblock Quantize {Transformers} models.

\bibitem[Anil et~al., 2023]{anil_palm_2023}
Anil, R., Dai, A.~M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., Chu, E., Clark, J.~H., Shafey, L.~E., Huang, Y., Meier-Hellstern, K., Mishra, G., Moreira, E., Omernick, M., Robinson, K., Ruder, S., Tay, Y., Xiao, K., Xu, Y., Zhang, Y., Abrego, G.~H., Ahn, J., Austin, J., Barham, P., Botha, J., Bradbury, J., Brahma, S., Brooks, K., Catasta, M., Cheng, Y., Cherry, C., Choquette-Choo, C.~A., Chowdhery, A., Crepy, C., Dave, S., Dehghani, M., Dev, S., Devlin, J., Díaz, M., Du, N., Dyer, E., Feinberg, V., Feng, F., Fienber, V., Freitag, M., Garcia, X., Gehrmann, S., Gonzalez, L., Gur-Ari, G., Hand, S., Hashemi, H., Hou, L., Howland, J., Hu, A., Hui, J., Hurwitz, J., Isard, M., Ittycheriah, A., Jagielski, M., Jia, W., Kenealy, K., Krikun, M., Kudugunta, S., Lan, C., Lee, K., Lee, B., Li, E., Li, M., Li, W., Li, Y., Li, J., Lim, H., Lin, H., Liu, Z., Liu, F., Maggioni, M., Mahendru, A., Maynez, J., Misra, V., Moussalem, M., Nado, Z., Nham, J., Ni, E., Nystrom, A., Parrish, A., Pellat, M., Polacek, M., Polozov, A., Pope, R., Qiao, S., Reif, E., Richter, B., Riley, P., Ros, A.~C., Roy, A., Saeta, B., Samuel, R., Shelby, R., Slone, A., Smilkov, D., So, D.~R., Sohn, D., Tokumine, S., Valter, D., Vasudevan, V., Vodrahalli, K., Wang, X., Wang, P., Wang, Z., Wang, T., Wieting, J., Wu, Y., Xu, K., Xu, Y., Xue, L., Yin, P., Yu, J., Zhang, Q., Zheng, S., Zheng, C., Zhou, W., Zhou, D., Petrov, S., and Wu, Y. (2023).
\newblock {PaLM} 2 {Technical} {Report}.
\newblock arXiv:2305.10403 [cs].

\bibitem[AWS, 2023]{noauthor_quickly_2023}
AWS (2023).
\newblock Quickly build high-accuracy {Generative} {AI} applications on enterprise data using {Amazon} {Kendra}, {LangChain}, and large language models {\textbar} {AWS} {Machine} {Learning} {Blog}.
\newblock Section: Amazon Kendra.

\bibitem[Brown et~al., 2020]{brown_language_2020}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. (2020).
\newblock Language {Models} are {Few}-{Shot} {Learners}.
\newblock arXiv:2005.14165 [cs].

\bibitem[Chen, 2021]{chen_improving_2021}
Chen, H. (2021).
\newblock Improving {Out}-of-{Domain} {Question} {Answering} with {Mixture} of {Experts}.

\bibitem[Chung et~al., 2022]{chung_scaling_2022}
Chung, H.~W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., Webson, A., Gu, S.~S., Dai, Z., Suzgun, M., Chen, X., Chowdhery, A., Castro-Ros, A., Pellat, M., Robinson, K., Valter, D., Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H., Petrov, S., Chi, E.~H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.~V., and Wei, J. (2022).
\newblock Scaling {Instruction}-{Finetuned} {Language} {Models}.
\newblock arXiv:2210.11416 [cs].

\bibitem[Dai et~al., 2022a]{dai_dialog_2022}
Dai, Z., Chaganty, A.~T., Zhao, V., Amini, A., Rashid, Q.~M., Green, M., and Guu, K. (2022a).
\newblock Dialog {Inpainting}: {Turning} {Documents} into {Dialogs}.
\newblock Publisher: arXiv Version Number: 2.

\bibitem[Dai et~al., 2022b]{dai_promptagator_2022}
Dai, Z., Zhao, V.~Y., Ma, J., Luan, Y., Ni, J., Lu, J., Bakalov, A., Guu, K., Hall, K.~B., and Chang, M.-W. (2022b).
\newblock Promptagator: {Few}-shot {Dense} {Retrieval} {From} 8 {Examples}.
\newblock arXiv:2209.11755 [cs].

\bibitem[Dalton et~al., 2020]{dalton_trec_2020}
Dalton, J., Xiong, C., and Callan, J. (2020).
\newblock {TREC} {CAsT} 2019: {The} {Conversational} {Assistance} {Track} {Overview}.
\newblock arXiv:2003.13624 [cs].

\bibitem[Dasigi et~al., 2021]{dasigi_dataset_2021}
Dasigi, P., Lo, K., Beltagy, I., Cohan, A., Smith, N.~A., and Gardner, M. (2021).
\newblock A {Dataset} of {Information}-{Seeking} {Questions} and {Answers} {Anchored} in {Research} {Papers}.
\newblock arXiv:2105.03011 [cs].

\bibitem[Devlin et~al., 2019]{devlin_bert_2019}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019).
\newblock {BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}.
\newblock arXiv:1810.04805 [cs].

\bibitem[Dimitrakis et~al., 2020]{dimitrakis_survey_2020}
Dimitrakis, E., Sgontzos, K., and Tzitzikas, Y. (2020).
\newblock A survey on question answering systems over linked data and documents.
\newblock {\em Journal of Intelligent Information Systems}, 55(2):233--259.

\bibitem[Ding et~al., 2022]{ding_v-doc_2022}
Ding, Y., Huang, Z., Wang, R., Zhang, Y., Chen, X., Ma, Y., Chung, H., and Han, S.~C. (2022).
\newblock V-{Doc} : {Visual} questions answers with {Documents}.
\newblock arXiv:2205.13724 [cs].

\bibitem[Elgohary et~al., 2019]{elgohary_can_2019}
Elgohary, A., Peskov, D., and Boyd-Graber, J. (2019).
\newblock Can {You} {Unpack} {That}? {Learning} to {Rewrite} {Questions}-in-{Context}.
\newblock In {\em Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})}, pages 5918--5924, Hong Kong, China. Association for Computational Linguistics.

\bibitem[Etezadi and Shamsfard, 2023]{etezadi_state_2023}
Etezadi, R. and Shamsfard, M. (2023).
\newblock The state of the art in open domain complex question answering: a survey.
\newblock {\em Applied Intelligence}, 53(4):4124--4144.

\bibitem[Farea et~al., 2022]{farea_evaluation_2022}
Farea, A., Yang, Z., Duong, K., Perera, N., and Emmert-Streib, F. (2022).
\newblock Evaluation of {Question} {Answering} {Systems}: {Complexity} of judging a natural language.
\newblock arXiv:2209.12617 [cs].

\bibitem[Ferrucci, 2012]{ferrucci_introduction_2012}
Ferrucci, D.~A. (2012).
\newblock Introduction to “{This} is {Watson}”.
\newblock {\em IBM Journal of Research and Development}, 56(3.4):1:1--1:15.
\newblock Conference Name: IBM Journal of Research and Development.

\bibitem[Frantar and Alistarh, 2023]{frantar_sparsegpt_2023}
Frantar, E. and Alistarh, D. (2023).
\newblock {SparseGPT}: {Massive} {Language} {Models} {Can} {Be} {Accurately} {Pruned} in {One}-{Shot}.

\bibitem[Frantar et~al., 2023a]{frantar_gptq_2023}
Frantar, E., Ashkboos, S., Hoefler, T., and Alistarh, D. (2023a).
\newblock {GPTQ}: {Accurate} {Post}-{Training} {Quantization} for {Generative} {Pre}-trained {Transformers}.
\newblock arXiv:2210.17323 [cs].

\bibitem[Frantar et~al., 2023b]{frantar_optimal_2023}
Frantar, E., Singh, S.~P., and Alistarh, D. (2023b).
\newblock Optimal {Brain} {Compression}: {A} {Framework} for {Accurate} {Post}-{Training} {Quantization} and {Pruning}.
\newblock arXiv:2208.11580 [cs].

\bibitem[Gao et~al., 2022]{gao_neural_2022}
Gao, J., Xiong, C., Bennett, P., and Craswell, N. (2022).
\newblock Neural {Approaches} to {Conversational} {Information} {Retrieval}.
\newblock arXiv:2201.05176 [cs].

\bibitem[GCS, 2023]{noauthor_generative_nodate}
GCS (2023).
\newblock Generative {AI} applications with {Vertex} {AI} {PaLM} 2 {Models} and {LangChain}.

\bibitem[Gholami et~al., 2021]{gholami_survey_2021}
Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.~W., and Keutzer, K. (2021).
\newblock A {Survey} of {Quantization} {Methods} for {Efficient} {Neural} {Network} {Inference}.
\newblock arXiv:2103.13630 [cs].

\bibitem[Gholami and Noori, 2021]{gholami_zero-shot_2021}
Gholami, S. and Noori, M. (2021).
\newblock Zero-{Shot} {Open}-{Book} {Question} {Answering}.
\newblock arXiv:2111.11520 [cs].

\bibitem[Green et~al., 1961]{green_baseball_1961}
Green, B.~F., Wolf, A.~K., Chomsky, C., and Laughery, K. (1961).
\newblock Baseball: an automatic question-answerer.
\newblock In {\em Papers presented at the {May} 9-11, 1961, western joint {IRE}-{AIEE}-{ACM} computer conference}, {IRE}-{AIEE}-{ACM} '61 ({Western}), pages 219--224, New York, NY, USA. Association for Computing Machinery.

\bibitem[Gu et~al., 2023]{gu_knowledge_2023}
Gu, Y., Dong, L., Wei, F., and Huang, M. (2023).
\newblock Knowledge {Distillation} of {Large} {Language} {Models}.
\newblock arXiv:2306.08543 [cs].

\bibitem[Gupta et~al., 2020]{gupta_conversational_2020}
Gupta, S., Rawat, B. P.~S., and Yu, H. (2020).
\newblock Conversational {Machine} {Comprehension}: a {Literature} {Review}.
\newblock In {\em Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}}, pages 2739--2753, Barcelona, Spain (Online). International Committee on Computational Linguistics.

\bibitem[Gururangan et~al., 2020]{gururangan_dont_2020}
Gururangan, S., Marasović, A., Swayamdipta, S., Lo, K., Beltagy, I., Downey, D., and Smith, N.~A. (2020).
\newblock Don’t {Stop} {Pretraining}: {Adapt} {Language} {Models} to {Domains} and {Tasks}.
\newblock {\em Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages 8342--8360.
\newblock Conference Name: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics Place: Online Publisher: Association for Computational Linguistics.

\bibitem[Guu et~al., 2020]{guu_realm_2020}
Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M.-W. (2020).
\newblock {REALM}: {Retrieval}-{Augmented} {Language} {Model} {Pre}-{Training}.
\newblock arXiv:2002.08909 [cs].

\bibitem[Hao et~al., 2022]{hao_recent_2022}
Hao, T., Li, X., He, Y., Wang, F.~L., and Qu, Y. (2022).
\newblock Recent progress in leveraging deep learning methods for question answering.
\newblock {\em Neural Computing and Applications}, 34(4):2765--2783.

\bibitem[Harabagiu et~al., 2003]{harabagiu_open-domain_2003}
Harabagiu, S.~M., Maiorano, S.~J., and Paşca, M.~A. (2003).
\newblock Open-domain textual question answering techniques.
\newblock {\em Natural Language Engineering}, 9(3):231--267.
\newblock Publisher: Cambridge University Press.

\bibitem[He et~al., 2020]{he_deberta_2020}
He, P., Liu, X., Gao, J., and Chen, W. (2020).
\newblock {DEBERTA}: {DECODING}-{ENHANCED} {BERT} {WITH} {DISENTANGLED} {ATTENTION}.

\bibitem[Hinton et~al., 2015]{hinton_distilling_2015}
Hinton, G., Vinyals, O., and Dean, J. (2015).
\newblock Distilling the {Knowledge} in a {Neural} {Network}.
\newblock arXiv:1503.02531 [cs, stat].

\bibitem[Houlsby et~al., 2019]{houlsby_parameter-efficient_2019}
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., de~Laroussilhe, Q., Gesmundo, A., Attariyan, M., and Gelly, S. (2019).
\newblock Parameter-{Efficient} {Transfer} {Learning} for {NLP}.
\newblock arXiv:1902.00751 [cs, stat].

\bibitem[Hu et~al., 2021]{hu_lora_nodate}
Hu, E., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. (2021).
\newblock {LORA}: {LOW}-{RANK} {ADAPTATION} {OF} {LARGE} {LAN}- {GUAGE} {MODELS}.

\bibitem[Huang et~al., 2022]{huang_-context_2022}
Huang, Y., Chen, Y., Yu, Z., and McKeown, K. (2022).
\newblock In-context {Learning} {Distillation}: {Transferring} {Few}-shot {Learning} {Ability} of {Pre}-trained {Language} {Models}.
\newblock arXiv:2212.10670 [cs].

\bibitem[Huggingface, 2023]{noauthor_peft_nodate}
Huggingface (2023).
\newblock {PEFT}.

\bibitem[Izacard and Grave, 2021]{izacard_leveraging_2021}
Izacard, G. and Grave, E. (2021).
\newblock Leveraging {Passage} {Retrieval} with {Generative} {Models} for {Open} {Domain} {Question} {Answering}.
\newblock In {\em Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}}, pages 874--880, Online. Association for Computational Linguistics.

\bibitem[Jiang et~al., 2023]{jiang_lion_2023}
Jiang, Y., Chan, C., Chen, M., and Wang, W. (2023).
\newblock Lion: {Adversarial} {Distillation} of {Closed}-{Source} {Large} {Language} {Model}.
\newblock arXiv:2305.12870 [cs].

\bibitem[Johnson et~al., 2017]{johnson_billion-scale_2017}
Johnson, J., Douze, M., and Jégou, H. (2017).
\newblock Billion-scale similarity search with {GPUs}.
\newblock arXiv:1702.08734 [cs].

\bibitem[Jurafsky and Martin, 2023]{jurafsky_speech_2023}
Jurafsky, D. and Martin, J.~H. (2023).
\newblock {\em Speech and {Language} {Processing}}.
\newblock Palo Alto, 3 edition.

\bibitem[Karpukhin et~al., 2020]{karpukhin_dense_2020}
Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t. (2020).
\newblock Dense {Passage} {Retrieval} for {Open}-{Domain} {Question} {Answering}.
\newblock arXiv:2004.04906 [cs].

\bibitem[Khashabi et~al., 2022]{khashabi_unifiedqa-v2_2022}
Khashabi, D., Kordi, Y., and Hajishirzi, H. (2022).
\newblock {UnifiedQA}-v2: {Stronger} {Generalization} via {Broader} {Cross}-{Format} {Training}.
\newblock arXiv:2202.12359 [cs].

\bibitem[Khattab and Zaharia, 2020]{khattab_colbert_2020}
Khattab, O. and Zaharia, M. (2020).
\newblock {ColBERT}: {Efficient} and {Effective} {Passage} {Search} via {Contextualized} {Late} {Interaction} over {BERT}.
\newblock arXiv:2004.12832 [cs].

\bibitem[{Langchain}, 2023]{noauthor_langchain-ailangchain_nodate}
{Langchain} (2023).
\newblock langchain-ai/langchain: {Building} applications with {LLMs} through composability.

\bibitem[Langchain, 2023]{noauthor_question_nodate}
Langchain (2023).
\newblock Question {Answering} {\textbar} {Langchain}.

\bibitem[Lester et~al., 2021]{lester_power_2021}
Lester, B., Al-Rfou, R., and Constant, N. (2021).
\newblock The {Power} of {Scale} for {Parameter}-{Efficient} {Prompt} {Tuning}.
\newblock In {\em Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}}, pages 3045--3059, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

\bibitem[Lewis et~al., 2019]{lewis_bart_2019}
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. (2019).
\newblock {BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}.

\bibitem[Lewis et~al., 2021]{lewis_retrieval-augmented_2021}
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., Riedel, S., and Kiela, D. (2021).
\newblock Retrieval-{Augmented} {Generation} for {Knowledge}-{Intensive} {NLP} {Tasks}.
\newblock arXiv:2005.11401 [cs].

\bibitem[Li et~al., 2022a]{li_dit_2022}
Li, J., Xu, Y., Lv, T., Cui, L., Zhang, C., and Wei, F. (2022a).
\newblock {DiT}: {Self}-supervised {Pre}-training for {Document} {Image} {Transformer}.
\newblock arXiv:2203.02378 [cs].

\bibitem[Li et~al., 2022b]{li_explanations_2022}
Li, S., Chen, J., Shen, Y., Chen, Z., Zhang, X., Li, Z., Wang, H., Qian, J., Peng, B., Mao, Y., Chen, W., and Yan, X. (2022b).
\newblock Explanations from {Large} {Language} {Models} {Make} {Small} {Reasoners} {Better}.
\newblock arXiv:2210.06726 [cs].

\bibitem[Li and Liang, 2021]{li_prefix-tuning_2021}
Li, X.~L. and Liang, P. (2021).
\newblock Prefix-{Tuning}: {Optimizing} {Continuous} {Prompts} for {Generation}.
\newblock arXiv:2101.00190 [cs].

\bibitem[Ling et~al., 2023]{ling_domain_2023}
Ling, C., Zhao, X., Lu, J., Deng, C., Zheng, C., Wang, J., Chowdhury, T., Li, Y., Cui, H., Zhang, X., Zhao, T., Panalkar, A., Cheng, W., Wang, H., Liu, Y., Chen, Z., Chen, H., White, C., Gu, Q., Pei, J., and Zhao, L. (2023).
\newblock Domain {Specialization} as the {Key} to {Make} {Large} {Language} {Models} {Disruptive}: {A} {Comprehensive} {Survey}.
\newblock arXiv:2305.18703 [cs].

\bibitem[Liu et~al., 2022]{liu_few-shot_2022}
Liu, H., Tam, D., Muqeeth, M., Mohta, J., Huang, T., Bansal, M., and Raffel, C. (2022).
\newblock Few-{Shot} {Parameter}-{Efficient} {Fine}-{Tuning} is {Better} and {Cheaper} than {In}-{Context} {Learning}.
\newblock Publisher: arXiv Version Number: 2.

\bibitem[Liu et~al., 2021a]{liu_gpt_2021}
Liu, X., Zheng, Y., Du, Z., Ding, M., Qian, Y., Yang, Z., and Tang, J. (2021a).
\newblock {GPT} {Understands}, {Too}.
\newblock arXiv:2103.10385 [cs].

\bibitem[Liu et~al., 2021b]{liu_dense_2021}
Liu, Y., Hashimoto, K., Zhou, Y., Yavuz, S., Xiong, C., and Yu, P.~S. (2021b).
\newblock Dense {Hierarchical} {Retrieval} for {Open}-{Domain} {Question} {Answering}.
\newblock arXiv:2110.15439 [cs].

\bibitem[Liu et~al., 2019]{liu_roberta_2019}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V. (2019).
\newblock {RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}.

\bibitem[Liu et~al., 2023]{liu_llm-qat_2023}
Liu, Z., Oguz, B., Zhao, C., Chang, E., Stock, P., Mehdad, Y., Shi, Y., Krishnamoorthi, R., and Chandra, V. (2023).
\newblock {LLM}-{QAT}: {Data}-{Free} {Quantization} {Aware} {Training} for {Large} {Language} {Models}.
\newblock arXiv:2305.17888 [cs].

\bibitem[Liusie et~al., 2022]{liusie_university_nodate}
Liusie, A., Qian, M., Li, X., and Gales, M. (2022).
\newblock {UNIVERSITY} {OF} {CAMBRIDGE} {AT} {TREC} {CAST} 2022.

\bibitem[Luo et~al., 2022]{luo_choose_2022}
Luo, M., Hashimoto, K., Yavuz, S., Liu, Z., Baral, C., and Zhou, Y. (2022).
\newblock Choose {Your} {QA} {Model} {Wisely}: {A} {Systematic} {Study} of {Generative} and {Extractive} {Readers} for {Question} {Answering}.
\newblock arXiv:2203.07522 [cs].

\bibitem[Ma et~al., 2023]{ma_llm-pruner_2023}
Ma, X., Fang, G., and Wang, X. (2023).
\newblock {LLM}-{Pruner}: {On} the {Structural} {Pruning} of {Large} {Language} {Models}.
\newblock arXiv:2305.11627 [cs].

\bibitem[Mao et~al., 2023]{mao_large_2023}
Mao, K., Dou, Z., Chen, H., Mo, F., and Qian, H. (2023).
\newblock Large {Language} {Models} {Know} {Your} {Contextual} {Search} {Intent}: {A} {Prompting} {Framework} for {Conversational} {Search}.
\newblock Publisher: arXiv Version Number: 1.

\bibitem[Mathew et~al., 2021]{mathew_document_2021}
Mathew, M., Tito, R., Karatzas, D., Manmatha, R., and Jawahar, C.~V. (2021).
\newblock Document {Visual} {Question} {Answering} {Challenge} 2020.
\newblock arXiv:2008.08899 [cs].

\bibitem[McDonald et~al., 2022]{mcdonald_detect_2022}
McDonald, T., Tsan, B., Saini, A., Ordonez, J., Gutierrez, L., Nguyen, P., Mason, B., and Ng, B. (2022).
\newblock Detect, {Retrieve}, {Comprehend}: {A} {Flexible} {Framework} for {Zero}-{Shot} {Document}-{Level} {Question} {Answering}.
\newblock arXiv:2210.01959 [cs].

\bibitem[Meuschke et~al., 2023]{meuschke_benchmark_2023}
Meuschke, N., Jagdale, A., Spinde, T., Mitrović, J., and Gipp, B. (2023).
\newblock A {Benchmark} of {PDF} {Information} {Extraction} {Tools} using a {Multi}-{Task} and {Multi}-{Domain} {Evaluation} {Framework} for {Academic} {Documents}.
\newblock volume 13972, pages 383--405.
\newblock arXiv:2303.09957 [cs].

\bibitem[Mishra and Jain, 2016]{mishra_survey_2016}
Mishra, A. and Jain, S.~K. (2016).
\newblock A survey on question answering systems with classification.
\newblock {\em Journal of King Saud University - Computer and Information Sciences}, 28(3):345--361.

\bibitem[Nassiri and Akhloufi, 2023]{nassiri_transformer_2023}
Nassiri, K. and Akhloufi, M. (2023).
\newblock Transformer models used for text-based question answering systems.
\newblock {\em Applied Intelligence}, 53(9):10602--10635.

\bibitem[Neelakantan et~al., 2022]{neelakantan_text_2022}
Neelakantan, A., Xu, T., Puri, R., Radford, A., Han, J.~M., Tworek, J., Yuan, Q., Tezak, N., Kim, J.~W., Hallacy, C., Heidecke, J., Shyam, P., Power, B., Nekoul, T.~E., Sastry, G., Krueger, G., Schnurr, D., Such, F.~P., Hsu, K., Thompson, M., Khan, T., Sherbakov, T., Jang, J., Welinder, P., and Weng, L. (2022).
\newblock Text and {Code} {Embeddings} by {Contrastive} {Pre}-{Training}.
\newblock arXiv:2201.10005 [cs].

\bibitem[Ni et~al., 2021]{ni_large_2021}
Ni, J., Qu, C., Lu, J., Dai, Z., Ábrego, G.~H., Ma, J., Zhao, V.~Y., Luan, Y., Hall, K.~B., Chang, M.-W., and Yang, Y. (2021).
\newblock Large {Dual} {Encoders} {Are} {Generalizable} {Retrievers}.
\newblock arXiv:2112.07899 [cs].

\bibitem[Nishida et~al., 2018]{nishida_retrieve-and-read_2018}
Nishida, K., Saito, I., Otsuka, A., Asano, H., and Tomita, J. (2018).
\newblock Retrieve-and-{Read}: {Multi}-task {Learning} of {Information} {Retrieval} and {Reading} {Comprehension}.
\newblock In {\em Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}}, pages 647--656.
\newblock arXiv:1808.10628 [cs].

\bibitem[{OpenAI}, 2023]{noauthor_chatgpt_2023}
{OpenAI} (2023).
\newblock {ChatGPT} {Retrieval} {Plugin}.
\newblock original-date: 2023-03-23T06:06:22Z.

\bibitem[Owoicho et~al., 2022]{owoicho_trec_2022}
Owoicho, P., Dalton, J., Aliannejadi, M., Azzopardi, L., Trippas, J.~R., and Vakulenko, S. (2022).
\newblock {TREC} {CAsT} 2022: {Going} {Beyond} {User} {Ask} and {System} {Retrieve} with {Initiative} and {Response} {Generation}.

\bibitem[Pereira et~al., 2022]{pereira_visconde_2022}
Pereira, J., Fidalgo, R., Lotufo, R., and Nogueira, R. (2022).
\newblock Visconde: {Multi}-document {QA} with {GPT}-3 and {Neural} {Reranking}.

\bibitem[Raffel et~al., 2023]{raffel_exploring_2023}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P.~J. (2023).
\newblock Exploring the {Limits} of {Transfer} {Learning} with a {Unified} {Text}-to-{Text} {Transformer}.
\newblock arXiv:1910.10683 [cs, stat].

\bibitem[Rajpurkar et~al., 2016]{rajpurkar_squad_2016}
Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. (2016).
\newblock {SQuAD}: 100,000+ {Questions} for {Machine} {Comprehension} of {Text}.
\newblock arXiv:1606.05250 [cs].

\bibitem[Rastogi et~al., 2020]{rastogi_schema-guided_2020}
Rastogi, A., Zang, X., Sunkara, S., Gupta, R., and Khaitan, P. (2020).
\newblock Schema-{Guided} {Dialogue} {State} {Tracking} {Task} at {DSTC8}.

\bibitem[Reddy et~al., 2022]{reddy_synthetic_2022}
Reddy, R.~G., Iyer, B., Sultan, M.~A., Zhang, R., Sil, A., Castelli, V., Florian, R., and Roukos, S. (2022).
\newblock Synthetic {Target} {Domain} {Supervision} for {Open} {Retrieval} {QA}.
\newblock arXiv:2204.09248 [cs].

\bibitem[Reddy et~al., 2018]{reddy_coqa_2018}
Reddy, S., Chen, D., and Manning, C.~D. (2018).
\newblock {CoQA}: {A} {Conversational} {Question} {Answering} {Challenge}.

\bibitem[Roberts et~al., 2020]{roberts_how_2020}
Roberts, A., Raffel, C., and Shazeer, N. (2020).
\newblock How {Much} {Knowledge} {Can} {You} {Pack} {Into} the {Parameters} of a {Language} {Model}?
\newblock In {\em Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})}, pages 5418--5426, Online. Association for Computational Linguistics.

\bibitem[Robertson and Zaragoza, 2009]{robertson_probabilistic_2009}
Robertson, S. and Zaragoza, H. (2009).
\newblock The {Probabilistic} {Relevance} {Framework}: {BM25} and {Beyond}.
\newblock {\em Foundations and Trends in Information Retrieval}, 3:333--389.

\bibitem[Sachan et~al., 2023]{sachan_questions_2023}
Sachan, D.~S., Lewis, M., Yogatama, D., Zettlemoyer, L., Pineau, J., and Zaheer, M. (2023).
\newblock Questions {Are} {All} {You} {Need} to {Train} a {Dense} {Passage} {Retriever}.
\newblock arXiv:2206.10658 [cs].

\bibitem[Serban et~al., 2016]{serban_generating_2016}
Serban, I.~V., García-Durán, A., Gulcehre, C., Ahn, S., Chandar, S., Courville, A., and Bengio, Y. (2016).
\newblock Generating {Factoid} {Questions} {With} {Recurrent} {Neural} {Networks}: {The} {30M} {Factoid} {Question}-{Answer} {Corpus}.
\newblock In {\em Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})}, pages 588--598, Berlin, Germany. Association for Computational Linguistics.

\bibitem[Thakur et~al., 2021]{thakur_beir_2021}
Thakur, N., Reimers, N., Rücklé, A., Srivastava, A., and Gurevych, I. (2021).
\newblock {BEIR}: {A} {Heterogenous} {Benchmark} for {Zero}-shot {Evaluation} of {Information} {Retrieval} {Models}.
\newblock arXiv:2104.08663 [cs].

\bibitem[Tito et~al., 2021]{tito_document_2021}
Tito, R., Karatzas, D., and Valveny, E. (2021).
\newblock Document {Collection} {Visual} {Question} {Answering}.
\newblock volume 12822, pages 778--792.
\newblock arXiv:2104.14336 [cs].

\bibitem[Touvron et~al., 2023]{touvron_llama_2023}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C.~C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P.~S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E.~M., Subramanian, R., Tan, X.~E., Tang, B., Taylor, R., Williams, A., Kuan, J.~X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. (2023).
\newblock Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}.
\newblock arXiv:2307.09288 [cs].

\bibitem[Treviso et~al., 2023]{treviso_efficient_2023}
Treviso, M., Lee, J.-U., Ji, T., Aken, B.~V., Cao, Q., Ciosici, M.~R., Hassid, M., Heafield, K., Hooker, S., Raffel, C., Martins, P.~H., Martins, A. F.~T., Forde, J.~Z., Milder, P., Simpson, E., Slonim, N., Dodge, J., Strubell, E., Balasubramanian, N., Derczynski, L., Gurevych, I., and Schwartz, R. (2023).
\newblock Efficient {Methods} for {Natural} {Language} {Processing}: {A} {Survey}.
\newblock {\em Transactions of the Association for Computational Linguistics}, 11:826--860.

\bibitem[Voorhees, 1999]{voorhees_trec-8_1999}
Voorhees, E. (1999).
\newblock The {TREC}-8 {Question} {Answering} {Track} {Report}.

\bibitem[Voskarides et~al., 2020]{voskarides_query_2020}
Voskarides, N., Li, D., Ren, P., Kanoulas, E., and de~Rijke, M. (2020).
\newblock Query {Resolution} for {Conversational} {Search} with {Limited} {Supervision}.
\newblock In {\em Proceedings of the 43rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}}, pages 921--930.
\newblock arXiv:2005.11723 [cs].

\bibitem[Wang, 2022]{wang_modern_2022}
Wang, Z. (2022).
\newblock Modern {Question} {Answering} {Datasets} and {Benchmarks}: {A} {Survey}.
\newblock Publisher: arXiv Version Number: 1.

\bibitem[Wang et~al., 2019]{wang_multi-passage_2019}
Wang, Z., Ng, P., Ma, X., Nallapati, R., and Xiang, B. (2019).
\newblock Multi-passage {BERT}: {A} {Globally} {Normalized} {BERT} {Model} for {Open}-domain {Question} {Answering}.
\newblock arXiv:1908.08167 [cs].

\bibitem[Wei et~al., 2023]{wei_chain--thought_2023}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., and Zhou, D. (2023).
\newblock Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}.
\newblock arXiv:2201.11903 [cs].

\bibitem[White et~al., 2023]{white_prompt_2023}
White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., and Schmidt, D.~C. (2023).
\newblock A {Prompt} {Pattern} {Catalog} to {Enhance} {Prompt} {Engineering} with {ChatGPT}.
\newblock arXiv:2302.11382 [cs].

\bibitem[William, 2023]{william_autogptq_2023}
William (2023).
\newblock {AutoGPTQ}.
\newblock original-date: 2023-04-13T02:18:11Z.

\bibitem[Yang et~al., 2019]{yang_query_2019}
Yang, J.-H., Lin, S.-C., Lin, J., Tsai, M.-F., and Wang, C.-J. (2019).
\newblock Query and {Answer} {Expansion} from {Conversation} {History}.

\bibitem[Yang et~al., 2018]{yang_hotpotqa_2018}
Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W.~W., Salakhutdinov, R., and Manning, C.~D. (2018).
\newblock {HotpotQA}: {A} {Dataset} for {Diverse}, {Explainable} {Multi}-hop {Question} {Answering}.
\newblock arXiv:1809.09600 [cs].

\bibitem[Zaib et~al., 2021]{zaib_conversational_2021}
Zaib, M., Zhang, W.~E., Sheng, Q.~Z., Mahmood, A., and Zhang, Y. (2021).
\newblock Conversational {Question} {Answering}: {A} {Survey}.

\bibitem[Zamani et~al., 2023]{zamani_conversational_2023}
Zamani, H., Trippas, J.~R., Dalton, J., and Radlinski, F. (2023).
\newblock Conversational {Information} {Seeking}.
\newblock arXiv:2201.08808 [cs].

\bibitem[Zhang et~al., 2023a]{zhang_beam_2023}
Zhang, J., Zhang, H., Zhang, D., Liu, Y., and Huang, S. (2023a).
\newblock Beam {Retrieval}: {General} {End}-to-{End} {Retrieval} for {Multi}-{Hop} {Question} {Answering}.
\newblock arXiv:2308.08973 [cs].

\bibitem[Zhang et~al., 2023b]{zhang_survey_2023}
Zhang, Q., Chen, S., Xu, D., Cao, Q., Chen, X., Cohn, T., and Fang, M. (2023b).
\newblock A {Survey} for {Efficient} {Open} {Domain} {Question} {Answering}.
\newblock In {\em Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})}, pages 14447--14465, Toronto, Canada. Association for Computational Linguistics.

\bibitem[Zhao et~al., 2023]{zhao_survey_2023}
Zhao, W.~X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang, X., Liu, Z., Liu, P., Nie, J.-Y., and Wen, J.-R. (2023).
\newblock A {Survey} of {Large} {Language} {Models}.
\newblock arXiv:2303.18223 [cs].

\bibitem[Zhu et~al., 2021]{zhu_retrieving_2021}
Zhu, F., Lei, W., Wang, C., Zheng, J., Poria, S., and Chua, T.-S. (2021).
\newblock Retrieving and {Reading}: {A} {Comprehensive} {Survey} on {Open}-domain {Question} {Answering}.
\newblock arXiv:2101.00774 [cs].

\bibitem[Zhu et~al., 2023]{zhu_survey_2023}
Zhu, X., Li, J., Liu, Y., Ma, C., and Wang, W. (2023).
\newblock A {Survey} on {Model} {Compression} for {Large} {Language} {Models}.

\bibitem[Zhu et~al., 2022]{zhu_teach_nodate}
Zhu, Y., Liu, N., Xu, Z., Liu, X., Meng, W., and Wang, Y. (2022).
\newblock Teach {Less}, {Learn} {More}: {On} the {Undistillable} {Classes} in {Knowledge} {Distillation}.

\end{thebibliography}
