This thesis serves as an introduction guide for developing conversational question-answering systems tailored to specific use cases. Beginning with an extensive overview of the field in Section \ref{chap:grundlagen}, we delve into the essential algorithms and concepts necessary for constructing such systems.

Focusing on practical implementations, Section \ref{chap:main} narrows down the implementation landscape by focusing on conversational retrieval-augmented generators for question-answering. We outline a system comprising four distinct components: Extract, CQU, Retriever, and Reader. Each component addresses its own well-defined problem domain, shedding light on the major challenges associated with them. Notable contributions include the detailed breakdown of the often-overlooked Extract component into various operations and the identification of challenges faced by the Retriever component, both with the knowledge base and the evidence set for the Reader. Additionally, we dissect the tasks of the Reader component into smaller challenges and propose multiple existing and novel solutions to tackle them. Ultimately, the main contribution lies in providing a decision map for constructing a conversational question-answering system, based on the diverse components and implementation possibilities.

To validate the feasibility of the decision map, Section \ref{chap:eval} presents the construction and evaluation of a default system primarily based on zero-shot components. Various evaluation approaches are introduced, implemented, and tested within this framework. Notably, the component-wise evaluation using synthetic data yields insights into the feasibility of synthetic datasets for metric-based component evaluation. Challenges such as complex or abstract questions pose difficulties in using synthetic datasets containing tuples of question-answer pairs and evidence, particularly applicable for factoid questions. Furthermore, the performance of two smaller \gls{llm}s, \textit{leo-hessian-7B-chat} and \textit{Llama2-7B-chat}, is compared against \textit{gpt-3.5-turbo}. Performance issues in applications of the smaller \gls{llm}s are identified, necessitating considerations when utilizing them in conversational question-answering systems. These issues primarily revolve around consistency in text generation quality and the suitability of the \gls{llm}s for the role of a Reader in the conversational setting, attributed to their inferior capabilities compared to larger \gls{llm}s in identifying pertinent information from the evidence set.

In Section \ref{subsec:data-augmentation-quality}, we discuss the identified limitations of the chosen approaches, which is necessary reading for anyone interested in building their own conversational question-answering system and how to evaluate it.

\vspace{\baselineskip}
\noindent We recommend any reader interested in building their own conversational question-answering system to start with this thesis as a foundational guide. They can then proceed to build a basic system similar to Section \ref{sec:setup} and evaluate it in an end-to-end manner as described in Section \ref{subsec:rag-eval}. This approach provides the quickest way to understand the specific challenges of their use case and how to further iterate and improve their system.

\vspace{\baselineskip}
\noindent Regarding future work, we propose the following directions for research:
\begin{itemize}
    \item \textbf{Practical Feasibility of Conversational Question Answering Systems:} Evaluate the costs and user experience associated with implementing conversational question-answering systems, particularly considering the significant expenses linked with utilizing \gls{llm}s. This evaluation should delve into whether it is financially viable to construct a search system relying on \gls{llm}s, especially given the escalating costs associated with the growing complexity of utilized approaches and the increasing number of \gls{llm} inference runs required. 

    \item \textbf{Constrained System Design:} Develop a search system that strikes a balance between resource utilization and search result quality. This endeavor may entail amalgamating multiple system components, implementing post-processing techniques on the evidence set, and orchestrating a series of reader components to create a system capable of addressing diverse question types while maintaining efficient resource usage. Relying solely on \gls{llm}-based approaches, such as \gls{rag}, may not always be the optimal solution for all use cases and setups. It might be more resource-efficient to employ a combination of smaller \gls{llm}s for different subtasks, or to explore techniques like quantization and incorporating extractive readers as post-processing steps, among others.

    \item \textbf{Improving the Retriever Component:} Enhance the performance of the retriever component, specifically focusing on its ability to locate all relevant contexts within the evidence set. This endeavor could entail investigating novel methodologies, such as employing agent-like retrievers or capitalizing on the structural elements of documents to direct the extraction and retrieval process. E.g. aligning the retrieval process with the search strategies employed by humans, who often hierarchically navigate through documents to pinpoint relevant passages, may offer valuable insights for enhancing retriever performance.

    \item \textbf{PDF Data Extraction:} Develop a universal solution for extracting textual or multimodal information from PDFs. This includes addressing the challenges of existing extraction operations, which yield different document models and may produce inconsistent passages. 
\end{itemize}