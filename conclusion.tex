This thesis analyzes possibilities, proposes a framework and evaluates it for the implementation of a \gls{convqa} system for use-case specific data. Beginning with an extensive overview of the field in Section \ref{chap:grundlagen}, we delve into the essential algorithms and concepts necessary for constructing such systems.

Focusing on practical implementations, Section \ref{chap:main} narrows down the implementation landscape by focusing on conversational retrieval-augmented generators for question-answering. We outline a system comprising four distinct components: Extract, CQU, Retriever, and Reader. Each component addresses its own well-defined problem domain, shedding light on the major challenges associated with them. Notable contributions include the detailed breakdown of the often-overlooked Extract component into various operations and the identification of challenges faced by the Retriever component, both with the knowledge base and the evidence set for the Reader. Additionally, we dissect the tasks of the Reader component into smaller challenges and propose multiple existing and novel solutions to tackle them. Ultimately, the main contribution lies in providing a decision map for constructing a conversational question-answering system, based on the diverse components and implementation possibilities.

To validate the feasibility of the decision map, Chapter \ref{chap:eval} presents the construction and evaluation of a default system primarily based on zero-shot components. Various evaluation approaches are introduced, implemented, and tested within this framework.

Specifically, the component-wise evaluation using synthetic data provides insights into the feasibility of synthetic datasets for metric-based component evaluation. Challenges arise with complex or abstract questions, particularly applicable to non-factoid questions, making human-based end-to-end evaluation preferable at this stage. Future work could explore using LLM agents to automate evaluation for real-world, use-case-specific datasets.

Furthermore, the performance of two smaller LLMs, \textit{leo-hessian-7B-chat} and \textit{Llama2-7B-chat}, is compared against \textit{gpt-3.5-turbo}. Issues with the smaller LLMs, such as consistency in text generation quality and suitability as Readers, highlight considerations for their use in conversational question-answering systems.

Moreover, in the \gls{poc} utilizing state-of-the-art LLMs, the Retriever and Extractor components emerged as the main bottlenecks for \gls{convqa} systems. Even in search scenarios with clear search intent and minimal ambiguity, the Retriever struggled to retrieve the correct passages from the knowledge base. This issue likely stems from challenges within both the Extractor and Retriever components. There is a clear need for further research in this area to address the difficulties in retrieving all relevant contexts from the knowledge base. Additionally, there is a pressing need for a universal solution capable of efficiently extracting textual or multimodal information from PDF documents, which remains a significant challenge in the field.

Additionally, as system complexity increases, so does inference time and computational intensity, especially with LLM-based approaches. Balancing computational resources may involve using combinations of smaller LLMs or alternative approaches for different subtasks.

In Section \ref{subsec:data-augmentation-quality}, we discuss the identified limitations of the chosen approaches, which is necessary reading for anyone interested in building their own conversational question-answering system and how to evaluate it.

\vspace{\baselineskip}
We recommend any reader interested in building their own conversational question-answering system to start with this thesis as a foundational guide. They can then proceed to build a basic system similar to Section \ref{sec:setup} and evaluate it in an end-to-end manner as described in Section \ref{subsec:rag-eval}. This approach provides the quickest way to understand the specific challenges of their use case and how to further iterate and improve their system.

\vspace{\baselineskip}
\noindent Regarding future work, we propose the following directions for research:
\begin{itemize}
    \item \textbf{Practical Feasibility of Conversational Question Answering Systems:} Evaluate the costs and user experience associated with implementing conversational question-answering systems, particularly considering the significant expenses linked with utilizing \gls{llm}s. This evaluation should delve into whether it is financially viable to construct a search system relying on \gls{llm}s, especially given the escalating costs associated with the growing complexity of utilized approaches and the increasing number of \gls{llm} inference runs required. 

    \item \textbf{Constrained System Design:} Develop a search system that strikes a balance between resource utilization and search result quality. This endeavor may entail amalgamating multiple system components, implementing post-processing techniques on the evidence set, and orchestrating a series of reader components to create a system capable of addressing diverse question types while maintaining efficient resource usage. Relying solely on \gls{llm}-based approaches, such as \gls{rag}, may not always be the optimal solution for all use cases and setups. It might be more resource-efficient to employ a combination of smaller \gls{llm}s for different subtasks, or to explore techniques like quantization and incorporating extractive readers as post-processing steps, among others.

    \item \textbf{Improving the Retriever Component:} Enhance the performance of the retriever component, specifically focusing on its ability to locate all relevant contexts within the evidence set. This endeavor could entail investigating novel methodologies, such as employing agent-like retrievers or capitalizing on the structural elements of documents to direct the extraction and retrieval process. E.g. aligning the retrieval process with the search strategies employed by humans, who often hierarchically navigate through documents to pinpoint relevant passages, may offer valuable insights for enhancing retriever performance.

    \item \textbf{PDF Data Extraction:} Develop a universal solution for extracting textual or multimodal information from PDFs. This includes addressing the challenges of existing extraction operations, which yield different document models and may produce inconsistent passages. 
\end{itemize}